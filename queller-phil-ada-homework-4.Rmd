---
title: "Queller-Philip-ADA-homework-4"
author: "Phil Queller"
date: "5/9/2020"
output: html_document
---


## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:


```{r}

library(devtools)
library(scales)
library(collapse)
library(BBmisc)
library(patchwork)
library(tidyverse)
library(MASS)
library(AICcmodavg)
library(MuMIn)
library(dplyr)
library(tidycovid19)
library(lme4)


```

```{r}
merged <- download_merged_data(cached = TRUE)
merged <- merged %>%
  group_by(country, iso3c) %>%
  arrange(country, iso3c, date) %>%
  ## new code to replace NAs with zeros
  mutate(
    confirmed = ifelse(is.na(confirmed), 0, confirmed),
    deaths = ifelse(is.na(deaths), 0, deaths),
    recovered = ifelse(is.na(recovered), 0, recovered)
  ) %>%
  ## end of new code
  mutate(
    daily_confirmed = confirmed - lag(confirmed, n = 1),
    daily_deaths = deaths - lag(deaths, n = 1),
    daily_recovered = recovered - lag(recovered, n = 1)
  ) %>%
  mutate(
    daily_confirmed = replace_na(daily_confirmed, 0),
    daily_deaths = replace_na(daily_deaths, 0),
    daily_recovered = replace_na(daily_recovered, 0)
  ) %>%
  ungroup() %>%
  arrange(country, iso3c, date)

add_world1 <- merged %>%
  group_by(date) %>%
  arrange(date) %>%
  summarize(
    country = "World", iso3c = NA,
    confirmed = sum(confirmed, na.rm = TRUE),
    deaths = sum(deaths, na.rm = TRUE),
    recovered = sum(recovered, na.rm = TRUE),
    timestamp = fmode(timestamp)
  ) %>%
  mutate(
    daily_confirmed = confirmed - lag(confirmed, n = 1),
    daily_deaths = deaths - lag(deaths, n = 1),
    daily_recovered = recovered - lag(recovered, n = 1)
  ) %>%
  mutate(
    daily_confirmed = replace_na(daily_confirmed, 0),
    daily_deaths = replace_na(daily_deaths, 0),
    daily_recovered = replace_na(daily_recovered, 0)
  ) %>%
  ungroup() %>%
  arrange(country, iso3c, date)

add_world2 <- merged %>%
  group_by(country, iso3c) %>%
  summarize(
    population = fmode(population),
    land_area_skm = fmode(land_area_skm),
    timestamp = fmode(timestamp)
  ) %>%
  ungroup() %>%
  summarize(
    country = "World", iso3c = NA,
    population = sum(population, na.rm = TRUE),
    land_area_skm = sum(land_area_skm, na.rm = TRUE)
  ) %>%
  mutate(pop_density = population / land_area_skm)

add_world <- left_join(add_world1, add_world2, by = c("country", "iso3c"))
merged <- bind_rows(merged, add_world)

cv_data <- pivot_longer(merged,
  cols = c(
    "confirmed", "deaths", "recovered",
    "daily_confirmed", "daily_deaths", "daily_recovered"
  ),
  names_to = "variable", values_to = "cases"
) %>%
  arrange(country, variable, date) %>%
  rename(area = land_area_skm, density = pop_density) %>%
  mutate(rate = cases / population * 10^6) %>%
  ## new code to omit data before 2020-05-11
  filter(date < "2020-05-11")

```

```{r}

cv_summary <- function(d, country_list = "World",
                       plot = TRUE, facet = "country",
                       status = c("confirmed", "deaths", "recovered")) {

  # based on `wes_palettes()` color schemes GrandBudapest1, IsleofDogs1,
  # IsleofDogs2 from the {wesanderson} package
  my_palette <- c(
    "#5B1A18", "#FD6467", "#F1BB7B", "#D67236",
    "#0F0D0E", "#9986A5", "#79402E", "#CCBA72", "#D9D0D3", "#8D8680",
    "#EAD3BF", "#AA9486", "#B6854D", "#39312F", "#1C1718"
  )

  if (facet == "country") {
    fill <- "variable"
    n <- length(unique(d$variable)) / 2
    # need only half of unique # of variable (3)
  }

  if (facet == "variable") {
    fill <- "country"
    n <- length(country_list)
    # need number of countries
  }

  if ("All" %in% country_list) {
    country_list <- unique(d$country)
    country_list <- setdiff(country_list, "World")
  }

  if ("World" %in% country_list) {
    d <- d %>% filter(country %in% country_list)

    totals <- d %>%
      group_by(variable) %>%
      summarize(
        country = "World",
        cases = max(cases),
        population = max(population),
        area = max(area),
        density = max(density),
        rate = max(rate, na.rm = TRUE),
        on = max(date)
      ) %>%
      select(country, variable, cases, population, area, density, rate, on) %>%
      arrange(variable) %>%
      ungroup()
  }

  if ("World" %nin% country_list) {
    d <- d %>% filter(country %in% country_list)
    totals <- d %>%
      group_by(country, variable) %>%
      summarize(
        cases = max(cases),
        population = max(population),
        area = max(area),
        density = max(density),
        rate = max(rate, na.rm = TRUE),
        on = max(date),
        gdp_capita = fmode(gdp_capita),
        income = fmode(income),
        life_expectancy = fmode(life_expectancy),
        max_sd = max(soc_dist),
        max_mr = max(mov_rest)
      ) %>%
      select(
        country, variable, cases, population, area, density, rate,
        gdp_capita, income, life_expectancy, max_sd, max_mr, on
      ) %>%
      arrange(country, variable) %>%
      ungroup()
  }

  if (plot == TRUE) {
    cc <- filter(d, variable %in% status)
    cum_cases_plot <- ggplot(
      data = cc,
      # use the tidy evaluation pronoun .data to slice the chosen fill
      # variable from the data frame
      aes(
        x = date, y = cases + 1, color = .data[[fill]],
        fill = .data[[fill]]
      )
    ) +
      geom_point(size = 0.5) +
      geom_line() +
      # use the tidy evaluation pronoun .data to slice the chosen facet_wrap
      # variable from the data frame
      facet_wrap(~ .data[[facet]], ncol = 5) +
      xlab("Date") +
      ylab("Log Cumulative Cases") +
      scale_y_log10(
        breaks = trans_breaks("log10", function(x) 10^x),
        labels = trans_format("log10", math_format(10^.x))
      ) +
      scale_color_manual(
        aesthetics = c("color", "fill"),
        name = NULL, values = my_palette
      )

    dc <- filter(d, variable %in% paste0("daily_", status))
    daily_cases_plot <- ggplot(
      data = dc,
      aes(
        x = date, y = cases, color = .data[[fill]],
        fill = .data[[fill]]
      )
    ) +
      geom_point(size = 0.5) +
      geom_line() +
      facet_wrap(~ .data[[facet]], ncol = 5) +
      xlab("Date") +
      ylab("Daily Cases") +
      scale_color_manual(
        aesthetics = c("color", "fill"),
        name = NULL, values = my_palette
      )
  }

  if (plot == TRUE) {
    return(list(
      totals = totals,
      cum_cases_plot = cum_cases_plot,
      daily_cases_plot = daily_cases_plot
    ))
  } else {
    return(list(totals = totals))
  }
}
```

#CHALLENGE 1:

Use the dataset and function generated above to plot global data on confirmed coronavirus infections, deaths, and recoveries.

HINT: To do this, you will want to look at the various arguments of the function and its defaults, as well as at the structure of the data object returned by the function.


```{r}

x <- cv_summary(cv_data)

```

#CHALLENGE 2:

Use the dataset and function generated above to plot data on confirmed coronavirus infections, deaths, and recoveries for the “Group of Seven” (G7) countries, which are the largest IMF-advanced economies in the world (i.e., the US, United Kingdom, Canada, France, Germany, Italy, and Japan) plus China, Russia, and Iran. Facet your plots first by “country” and then by “variable”.

```{r}

cv_summary(cv_data, country_list = c("USA", "United Kingdom", "Canada", "France", "Germany", "Italy", "Japan", "Russia", "Iran"), 
           plot = TRUE, facet = "country")
```

```{r}

cv_summary(cv_data, country_list = c("USA", "United Kingdom", "Canada", "France", "Germany", "Italy", "Japan", "Russia", "Iran"), 
           plot = TRUE, facet = "variable")
```

#CHALLENGE 3:

Use the dataset and function generated above to return summary data for ALL countries in the dataset, and then filter this returned dataset to only those countries with populations of over 1 million, storing this dataset as a tibble d. How many countries does this tibble include?

HINT: You might want to set the plot= argument to “FALSE”, or at least not try to show a plot of the results for all countries as that will exceed the limits allowed for grid graphics.


```{r}
summary <- cv_summary(cv_data, plot = FALSE, country_list = "All")

t <- summary$totals %>% filter(population > 1000000)

length(unique(t$country))

```







CHALLENGE 4:

Filter d to generate two additional tibbles, overall and daily that include only data on the variables “confirmed” and “daily_confirmed” cases, respectively. Depending on the dataset, the case and rate variables either reflect the overall (i.e., across the pandemic) or maximum daily number of cases and number of cases recorded per million people in the population. Which 10 countries have experienced the highest over rate of confirmed cases? Which 10 countries have experienced the highest single-day rate of confirmed cases?


```{r}

overall <- t %>% filter(variable == "confirmed") 

daily <- t %>% filter(variable == "daily_confirmed")

toptenOverall <- overall %>% arrange(desc(cases)) %>%
                 slice(1:10)

toptenDailyMax <- daily  %>% arrange(desc(rate)) %>%
                 slice(1:10)
```

CHALLENGE 5:

Run a linear model to evaluate how the overall infection rate (rate) is related to the variables population density (density), population size (population), gross domestic product per capita (gdp_capita), and overall income level (income). In doing so, you should run exploratory visualizations to see whether or not the four numeric variables should be transformed.

Based on the full model, what predictors variables have slopes significantly different from zero?

```{r}

overall %>% ggplot(aes(x = density)) +
  geom_histogram()
#take the log of density to transform for normality
overall %>% ggplot(aes(x = log(density))) +
  geom_histogram()


overall %>% ggplot(aes(x = population)) +
  geom_histogram()
#take the log of population to transform for normality
overall %>% ggplot(aes(x = log(population))) +
  geom_histogram()

overall %>% ggplot(aes(x = gdp_capita)) +
  geom_histogram()
#take the log of gdp to transform for normality
overall %>% ggplot(aes(x = log(gdp_capita))) +
  geom_histogram()


overall %>% ggplot(aes(x = rate)) +
  geom_histogram()
#take the log of rate to transform for normality
overall %>% ggplot(aes(x = log(rate))) +
  geom_histogram()

fit <- lm(log(rate) ~ log(density) + log(population) + log(gdp_capita) + income, data = overall)
summary(fit)


```
CHALLENGE 6:

Run stepwise selection using AIC to evaluate whether the full model or a nested, simpler model is preferred. What is the best model (based on AIC) of the possible ones involving these 4 predictors? What are the “pseudo-R2” values associated with the full and “best” models?

HINT: Check out Module 22 on module selection using AIC with the {MASS} package and Module 24 on calculating “pseudo-R2” values with {MuMIn}.

Repeat this modeling process to evaluate what combination of explanatory variables best maximum daily infection rate. Are the important predictors the same? What additional or different variables are included?

```{r}

library(MASS)

mod_overall <- lm(log(rate) ~ log(density) + log(population) + log(gdp_capita) + income, data = overall)
s <- stepAIC(mod_overall, scope = . ~ ., direction = "both", na.rm = TRUE)
AIC_best <- lm(log(rate) ~ log(density) + log(gdp_capita), data = overall)

r.squaredGLMM(mod_overall)
r.squaredGLMM(AIC_best)


```
AIC indicates the best model from the "overall" tibble is log(rate) ~ log(density) + log(gdp_capita). This slightly lowers the pseudo-R2 value from 0.6108234 in the full model to 0.6057285 in the AIC best model.
 

```{r}

mod_daily <- lm(log(rate) ~ log(density) + log(population) + log(gdp_capita) + income, data = daily)
s <- stepAIC(mod_daily, scope = . ~ ., direction = "both", na.rm = TRUE)
AIC_best <- lm(log(rate) ~ log(density) + log(gdp_capita) + log(population), data = daily)

r.squaredGLMM(mod_daily)
r.squaredGLMM(AIC_best)



```
AIC indicates the best model from the "daily" tibble log(rate) ~ log(density) + log(population) + log(gdp_capita). Again, the pseudo-R2 values drop slightly from 0.5523888 in the full model to 0.5454554 in the AIC best model. The AIC best models between the daily and overall infection rates share density and gdp as strong explanatory variables. The AIC best model on daily infection rates also includes population as an explanatory variable. 


CHALLENGE 7:

To the best model you determined in CHALLENGE 6 for predicting the maximum daily infection rate, add in the maximum social distancing (max_sd) and maximum movement restriction (max_mr) score per country. Do either of these additional variable improve the model significantly?

```{r}

daily %>% ggplot(aes(x = max_mr)) +
  geom_histogram()

daily %>% ggplot(aes(x = log(max_mr))) +
  geom_histogram()

daily %>% ggplot(aes(x = max_mr)) +
  geom_histogram()

daily %>% ggplot(aes(x = log(max_mr))) +
  geom_histogram()

```
both new variables look better as is rather than log transformed

```{r}

soc <- lm(log(rate) ~ log(density) + log(gdp_capita) + log(population) + max_sd + max_mr, data = daily)
s <- stepAIC(soc, scope = . ~ ., direction = "both", na.rm = TRUE)
r.squaredGLMM(soc)


```
Yes, adding max_sd and max_mr increased the predictive power of the model. The AIC number decreased from 71.22 in the original AIC best model to 70.89 in the model that includes social distancing and movement restrictions. The psuedo-R2 also increased from 0.5454554 to 0.5501866. It does not change the three main predictor variables: gdp, density, and population. 



CHALLENGE 8:

Finally, let’s go back to the original cv_data tibble. we will now run a set of “mixed effects” model! First, filter the tibble to include only data for countries with a population of > 1 million and to include only those rows of data for daily_confirmed cases (i.e., variable == “daily_confirmed”). Also filter the dataset to only include rows where rate > 0 (i.e., where there was at least 1 new recorded cases on a day). Then, run a set of linear mixed effects models that include the fixed and random effects indicated in the table below. Start with the full model (4 fixed effects and 2 random effects) as m1 and then run nested models with different subsets of fixed predictors, but always keeping country and date as random effects. Use the lmer() function from the {lme4} package with the argument REML=FALSE specified, as discussed in Module 24. Then, construct an AIC table for the full set of models that you run, and be sure to run a null model with ONLY random effects. What is the best model of the complete set that you ran? What is the “pseudo-R2” value associated with that model?

```{r}

eight <- cv_data %>% filter(population > 1000000) %>%
      filter(variable == "daily_confirmed") %>%
      filter(rate > 0)

full <- lmer(log(rate) ~ log(density) + log(gdp_capita) + soc_dist + mov_rest + (1|country) + (1|date), REML = FALSE, data = eight)
# s <- stepAIC(m1, scope = . ~ ., direction = "both")
summary(full)
mod1 <- lmer(log(rate) ~ log(density) + log(gdp_capita) + soc_dist + (1|country) + (1|date), REML = FALSE, data = eight)
summary(mod1)

mod2 <- lmer(log(rate) ~ log(density) + log(gdp_capita) + mov_rest + (1|country) + (1|date), REML = FALSE, data = eight)
summary(mod2)

mod3 <- lmer(log(rate) ~ log(density) + soc_dist + mov_rest + (1|country) + (1|date), REML = FALSE, data = eight)
summary(mod3)

mod4 <- lmer(log(rate) ~ log(gdp_capita) + soc_dist + mov_rest + (1|country) + (1|date), REML = FALSE, data = eight)
summary(mod4)

mod5 <- lmer(log(rate) ~ log(density) + log(gdp_capita) + (1|country) + (1|date), REML = FALSE, data = eight)
summary(mod5)

mod6 <- lmer(log(rate) ~ soc_dist + mov_rest + (1|country) + (1|date), REML = FALSE, data = eight)
summary(mod6)

mod7 <- lmer(log(rate) ~ log(density) + mov_rest + (1|country) + (1|date), REML = FALSE, data = eight)
summary(mod7)

mod8 <- lmer(log(rate) ~ log(gdp_capita) + mov_rest + (1|country) + (1|date), REML = FALSE, data = eight)
summary(mod8)

null <- lmer(log(rate) ~ (1|country) + (1|date), REML = FALSE, data = eight)
summary(null)

# s <- stepAIC(null, scope = . ~ ., direction = "both")




```
I'm not able to get stepwise AIC to work on my model, so I've commented it out so my file will knit. If I could get it to work, I would look for the model that has the lowest AIC value. I manually ran 7 models and found log(density) was never a significant predictor. The best model used log(gdp_capita), soc_dist, and mov_rest as explanatory variables. They were significant in all models run. Interestingly, log(density) was nearly significant in the model: log(rate) ~ log(density) + log(gdp_capita) + mov_rest + (1 | country) + (1 | date), with a p-value of 0.0822. This demonstrates the importance of model selection. If I didn't run many models I might have thought density might be an important predictor if I only ran that moodel. I'll use backward selection as well. 


```{r}

full <- lmer(log(rate) ~ log(density) + log(gdp_capita) + soc_dist + mov_rest + (1|country) + (1|date), REML = FALSE, data = eight)
summary(full)

drop1(full, test = "F")

m1 <- update(full, . ~ . - log(density))

summary(m1)
r.squaredGLMM(m1)

summary(full)
r.squaredGLMM(full)

summary(null)
r.squaredGLMM(null)


```
The best model is log(rate) ~ log(gdp_capita) + log(soc_dist) + log(mov_rest). The psuedo-R2 of the optimal model using backwards selection is 0.2937965, which is slightly higher than the full model (0.2921158). The psuedo-R2 of the null model is 0.8282165 for the null model, but neither of the random effects are significant. Using backwards selection to make m1 resulted in the best model. 




